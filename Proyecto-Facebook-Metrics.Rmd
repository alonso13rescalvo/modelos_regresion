---
title: "Proyecto-Facebook-Metrics"
author: "Cristina, Lucia, Alonso"
date: "2025-02-09"
output: 
  html_document:
      theme: journal
      toc: yes
      toc_depth: 6
      toc_float: yes
editor_options: 
  markdown: 
    wrap: sentence
---

```{r}

library(ggplot2)
library(dplyr)
library(knitr)
#library(gt)
library(pheatmap)

```

# Introducción

**Información de los autores** Este proyecto ha sido realizado por el grupo 9 del grado de Ciencia e Ingeniería de datos para la asignatura de Modelos de Regresión que cuanta con los siguientes integrantes:

-   **Cristina Rodríguez Ayllón**
-   **Lucía Arnaldo Cuevas**
-   **Alonso Rescalvo Casas**

Nuestro datasetes es el de "Facebook Metrics Dataset".
Es un conjunto de datos que recopila diversas métricas relacionadas con la interacción de los usuarios en páginas de Facebook.
Estas métricas incluyen información sobre impresiones, alcance, interacciones con publicaciones, entre otras.

```{r lectura, warning=FALSE}
# lectura de datos en csv
#dataset_Facebook <- read.csv("datos/dataset_Facebook.csv", stringsAsFactors = FALSE)
# Cambiamos el nombre de las variables 

library(readr)
dataset_Facebook <- read_delim("datos/dataset_Facebook.csv", 
    delim = ";", escape_double = FALSE, trim_ws = TRUE)


#datos<-read.csv("datos/datos.csv")
ntotal <- dim(dataset_Facebook)[1] # numero de observaciones
ptotal <- dim(dataset_Facebook)[2] # numero de columnas



```

Comprobamos que tenemos $n=$`r ntotal` observaciones y $p=$`r ptotal` variables en la base de datos.

Según la descripción oficial de los datos, las variables que conforman el conjunto de datos son:

(aqui iria da descripcion de las varibles y tal, la tablita que hizo Alonso)

# EDA

## Preguntas a resolver pre-EDA

(preguntas alonso)

**Variable objetivo: ¿Existe una variable de "respuesta"? ¿Binaria o multiclase?** Sí, la variable de respuesta es "Total Interactions".
Como estamos en un proyecto de regresión, esta variable es numérica continua y no es binaria ni multiclase.

**¿Es posible identificar variables irrelevantes?. Estudiar variables relevantes requiere, habitualmente, métodos estadísticos.** Sí, pero para hacerlo correctamente hay que aplicar métodos estadísticos como matrices de correlación.

**¿Es posible identificar la distribución que siguen las variables?** Sí, se puede hacer con gráficos y pruebas estadísticas como: + Histogramas para visualizar la forma de la distribución.
+ Boxplots para detectar outliers y asimetrías.
+ Q-Q Plots para comparar con una distribución normal.
+ Pruebas estadísticas como Shapiro-Wilk o Kolmogorov-Smirnov para evaluar normalidad.

(preguntas lucía)

## Partición de los datos

Realizamos la división de nuestros datos en 3 muestras: entrenamiento, validación y test.

```{r particion}
# mediante una semilla conseguimos que el ejercicio sea reproducible
set.seed(1)


# creamos índices
indices <- 1:ntotal
ntrain <- ntotal * .5
ntest <- ntotal * .25
nval <- ntotal - (ntrain+ntest)
indices.train <- sample(indices, ntrain, replace = FALSE)
indices.test <- sample(indices[-indices.train],ntest,replace=FALSE)
indices.val <- indices[-c(indices.train,indices.test)]

# Usamos el 50% de la base de datos como conjunto de entrenamiento
# 25% para test
# 25% para validación
train <- dataset_Facebook[indices.train,]
test  <- dataset_Facebook[indices.test,]
val   <- dataset_Facebook[indices.val, ]


```

## Estudio de las variables

La idea es que vayamos viendo que distribucion sigue cada variables (con un histograma), si hay valores atipicos (con un boxplot) y enfrentarlas con el target

### Target

**Total Interactions**

```{r}

summary(train$`Total Interactions`)


```

```{r}
#Histograma(Para ver la forma de la distribución):

library(ggplot2)
ggplot(train, aes(x = `Total Interactions`)) +
  geom_histogram(binwidth = 50, fill = "lightblue", color = "black") +
  theme_minimal() +
  labs(title = "Distribución del Target (Total Interactions)", x = "Total Interactions", y = "Frecuencia")

```

```{r}
#Boxplot(Para detectar outliers):

ggplot(train, aes(y = `Total Interactions`)) +
  geom_boxplot(fill = "lightblue", color = "black", outlier.colour = "red") +
  theme_minimal() +
  labs(title = "Boxplot del Target (Total Interactions)", y = "Total Interactions")
```

```{r}
library(pheatmap)

# Seleccionar solo variables numéricas
numeric_vars <- train[, sapply(train, is.numeric)]

# Calcular la matriz de correlación
cor_matrix <- cor(numeric_vars, use = "complete.obs")

# Renombrar las variables con nombres más cortos
colnames(cor_matrix) <- c("1", "2", "3", "4","5", "6", "7", "8","9", "10", "11", "12","13", "14", "15", "16", "17", "18" )  # Edita según tus variables
rownames(cor_matrix) <- colnames(cor_matrix)  # Para que las filas tengan el mismo nombre

# Crear heatmap con nombres cortos
pheatmap(cor_matrix, display_numbers = TRUE, 
         color = colorRampPalette(c("#98F5FF", "white", "#AB82FF"))(50))

```

### Variables

**Page total likes**

```{r}

summary(train$`Page total likes`)

```

El análisis de la variable Page total likes muestra que los valores oscilan entre un mínimo de 81,370 y un máximo de 139,441.
La mediana se sitúa en 128,032, mientras que la media es ligeramente menor, con un valor de 122,570, lo que sugiere una leve asimetría hacia la izquierda.
Esto indica que la mayoría de las publicaciones tienen un número de likes relativamente alto, concentrándose entre los valores de 120,000 y 140,000, aunque existen algunas con menos de 100,000 likes.

```{r}
# Cargar librerías necesarias
library(ggplot2)

# Histograma de "Page total likes" en el conjunto de entrenamiento
ggplot(train, aes(x = train$`Page total likes`)) + 
  geom_histogram(binwidth = 500, fill = "lightblue", color = "black", alpha = 0.7) + 
  theme_minimal() +
  labs(title = "Distribución de Page total likes (Train)", x = "Page total likes", y = "Frecuencia")


```

Al observar el histograma, se aprecia que la distribución de los likes no es completamente uniforme, sino que tiende a agruparse en los valores más elevados.

```{r}
# Boxplot de "Page total likes" en el conjunto de entrenamiento
ggplot(train, aes(y = train$`Page total likes`)) + 
  geom_boxplot(fill = "lightblue", color = "black", outlier.colour = "red", outlier.size = 2) +
  theme_minimal() +
  labs(title = "Boxplot de Page total likes (Train)", y = "Page total likes")

```

El boxplot refuerza esta idea, mostrando que la mayor parte de los datos se encuentra dentro de un rango definido, sin valores extremos que se consideren atípicos.

```{r}
# Cargar librerías necesarias
library(ggplot2)

#  Page total likes
cor(train$`Total Interactions`, train$`Page total likes`, use="complete.obs")  # Correlación
plot(train$`Page total likes`, train$`Total Interactions`, 
     main="Page Total Likes vs Total Interactions",
     xlab="Page Total Likes", ylab="Total Interactions", 
     col="red", pch=16)
```

En cuanto a la relación entre Page total likes y Total Interactions, la correlación obtenida es baja o moderada, lo que indica que el número de likes en una página no determina de manera significativa el nivel de interacción de sus publicaciones.
El diagrama de dispersión confirma esta observación, ya que no se percibe una tendencia clara entre ambas variables.
Hay casos en los que páginas con un menor número de likes generan una gran cantidad de interacciones, mientras que otras con más likes no necesariamente logran el mismo nivel de engagement.

Esto sugiere que la cantidad de likes en una página no es el único factor que influye en la interacción del público.
Es probable que variables como el tipo de publicación, la hora en la que se publica o el contenido del mensaje tengan un impacto mayor en el número de interacciones.

```{r}
trainmod <- train %>%
  mutate(Page_total_likes_group = cut(`Page total likes`, breaks = 5))  # Agrupamos en intervalos

tabla_frecuencias_likes <- trainmod %>%
  count(Page_total_likes_group) %>%
  mutate(f = n / nrow(train),
         N = cumsum(n),
         F = cumsum(f))

knitr::kable(tabla_frecuencias_likes, digits = 4)
```

**Type**

```{r}
summary(train$`Type`) 

```

```{r}
table(train$Type)


```

```{r}
#  Type (Gráfico de cajas ya que es una variable categórica)
ggplot(train, aes(x = Type, y = `Total Interactions`, fill = Type)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Total Interactions por Type", 
       x = "Type", y = "Total Interactions")


```

```{r}

tabla_frecuencias_type <- train %>%
  count(Type) %>%
  mutate(f = n / nrow(train),
         N = cumsum(n),
         F = cumsum(f))

knitr::kable(tabla_frecuencias_type, digits = 4)


```

**Category**

```{r}
summary(train$Category)
table(train$Category)

```

```{r}

# Cargar librerías necesarias
library(ggplot2)

# Histograma de "Page total likes" en el conjunto de entrenamiento
ggplot(train, aes(x = train$Category)) + 
  geom_histogram(binwidth = 500, fill = "lightblue", color = "black", alpha = 0.7) + 
  theme_minimal() +
  labs(title = "Distribución de Page total likes (Train)", x = "Page total likes", y = "Frecuencia")



#  Category (Gráfico de cajas)
ggplot(train, aes(x = as.factor(Category), y = `Total Interactions`, fill = as.factor(Category))) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Total Interactions por Category", 
       x = "Category", y = "Total Interactions")
```

```{r}
# Boxplot de "Page total likes" en el conjunto de entrenamiento
ggplot(train, aes(y = train$Category)) + 
  geom_boxplot(fill = "lightblue", color = "black", outlier.colour = "red", outlier.size = 2) +
  theme_minimal() +
  labs(title = "Boxplot de Page total likes (Train)", y = "Page total likes")

```

```{r}

tabla_frecuencias_category <- train %>%
  count(Category) %>%
  mutate(f = n / nrow(train),
         N = cumsum(n),
         F = cumsum(f))

knitr::kable(tabla_frecuencias_category, digits = 4)


```

**Post Month**

```{r}
summary(train$`Post Month`)
table(train$`Post Month`)

```

```{r}
#  Post Month (Gráfico de cajas)
ggplot(train, aes(x = as.factor(`Post Month`), y = `Total Interactions`, fill = as.factor(`Post Month`))) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Total Interactions por Post Month", 
       x = "Post Month", y = "Total Interactions")
```

```{r}

tabla_frecuencias_month <- train %>%
  count(`Post Month`) %>%
  mutate(f = n / nrow(train),
         N = cumsum(n),
         F = cumsum(f))

knitr::kable(tabla_frecuencias_month, digits = 4)


```

**Post Weekday**

```{r}
summary(train$`Post Weekday`)
table(train$`Post Weekday`)

```

```{r}
#  Post Weekday (Gráfico de cajas)
ggplot(train, aes(x = as.factor(`Post Weekday`), y = `Total Interactions`, fill = as.factor(`Post Weekday`))) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Total Interactions por Post Month", 
       x = "Post Weekday", y = "Total Interactions")
```

```{r}

tabla_frecuencias_weekday <- train %>%
  count(`Post Weekday`) %>%
  mutate(f = n / nrow(train),
         N = cumsum(n),
         F = cumsum(f))

knitr::kable(tabla_frecuencias_weekday, digits = 4)


```

**Post Hour**

```{r}
summary(train$`Post Hour`)
table(train$`Post Hour`)
```

```{r}
#  Post Hour (Gráfico de cajas)
ggplot(train, aes(x = as.factor(`Post Hour`), y = `Total Interactions`, fill = as.factor(`Post Hour`))) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Total Interactions por Post Month", 
       x = "Post Hour", y = "Total Interactions")
```

```{r}

tabla_frecuencias_hour <- train %>%
  count(`Post Hour`) %>%
  mutate(f = n / nrow(train),
         N = cumsum(n),
         F = cumsum(f))

knitr::kable(tabla_frecuencias_hour, digits = 4)
```

**Paid**

**Lifetime Post Total Reach**

**Lifetime Post Total Impressions**

**Lifetime Engaged Users**

**Lifetime Post Consumers**

**Lifetime Post Consumptions**

**Lifetime Post Impressions by people who have liked your Page**

**Lifetime Post reach by people who like your Page**

**Lifetime People who have liked your Page and engaged with your post**

**Comment**

**Like**

**Share**

# Regresión lineal pruebas

```{r}
# Eliminar filas con valores faltantes en cualquier columna
train_clean <- na.omit(train)

# Verificar que no hay valores faltantes después de la limpieza
colSums(is.na(train_clean))
```

**1: Ajustar el modelo de regresión lineal**

Ajustamos el modelo: Estamos ajustando un modelo de regresión lineal simple donde la variable dependiente es Total Interactions y la variable predictora es Page total likes.
Ajustamos el modelo y calculamos los coeficientes de la recta de regresión.

Obtener estimadores: Extraemos los coeficientes del modelo (intercepto y pendiente) junto con sus errores estándar, valores t y p-valores.

Esto nos permite entender la relación entre Page total likes y Total Interactions.

```{r}
# Ajustar el modelo de regresión lineal
modelo <- lm(`Total Interactions` ~ `like`, data = train_clean)

# Obtener estimadores de los parámetros y errores estándar
estimadores <- coef(summary(modelo))  # Incluye estimadores y errores estándar

# Imprimir los resultados
cat("Estimadores para los parámetros del modelo:\n")
print(estimadores)
```

Se ajustó un modelo de regresión lineal simple para analizar la relación entre la variable independiente "Likes" y la variable dependiente "Total Interactions". La ecuación estimada del modelo es la siguiente:

Total_Interactions = 10.96 + 1.124 × like

Los resultados del modelo indican lo siguiente:

  + Intercepto (β_0=10.96): Representa el valor esperado de interacciones totales cuando el número de "likes" es cero.
  + Pendiente (β_1=1.124): Indica que, en promedio, cada "like" adicional se asocia con un incremento de 1.124 interacciones totales.

Para evaluar la significancia de los coeficientes, se analizaron sus respectivos errores estándar, valores t y p-valores.

  + El p-valor asociado a la variable "like" es extremadamente pequeño (3.09×10^−259), lo que indica que su influencia en el modelo es altamente significativa. Asimismo, su t-valor es considerablemente alto (174.87), lo que refuerza su importancia en la predicción de interacciones totales.

  + Dado que ambos p-valores son menores a 0.05, se concluye que los coeficientes son estadísticamente significativos, lo que valida la relación entre los "likes" y las interacciones totales.



**2: Resumen del modelo**

```{r}
# Obtener resumen del modelo
summary(modelo)
```

**3: Tabla ANOVA**

```{r}
# Obtener y mostrar la tabla ANOVA
tabla_anova <- anova(modelo)
cat("\nTabla ANOVA:\n")
print(tabla_anova)
```
Suma de Cuadrados (Sum Sq):
  + La variabilidad explicada por la variable "like" en el modelo es 13555096, lo que representa una proporción significativa de la variabilidad total en "Total Interactions".
  + La variabilidad residual es de 108599, lo que sugiere que la mayor parte de la variabilidad en las interacciones totales es explicada por la variable "like".

Valor F:
  + El estadístico F = 30580 indica cuántas veces la variabilidad explicada por el modelo es mayor que la variabilidad no explicada. Un valor F tan alto sugiere que el modelo es altamente significativo.

Significancia del Modelo (p-valor):
  + El p-valor es < 2.2e-16, lo que es significativamente menor al umbral habitual de 0.05.
  + Esto indica que existe una relación estadísticamente significativa entre "like" y "Total Interactions", descartando la posibilidad de que la relación observada sea producto del azar.


**4: Estudiar los residuos**

Gráfico de residuos vs. valores ajustados

```{r}
# Obtener los residuos
residuos <- resid(modelo)

# 1. Gráfico de residuos vs. valores ajustados
valores_ajustados <- fitted(modelo)
plot(valores_ajustados, residuos,
     main = "Residuos vs Valores Ajustados",
     xlab = "Valores Ajustados",
     ylab = "Residuos",
     pch = 19, col = "blue")
abline(h = 0, col = "red", lwd = 2)
```

Este gráfico muestra la relación entre los residuos y los valores ajustados por el modelo. Se observa que la dispersión de los puntos no es completamente homogénea, ya que hay una mayor concentración en los valores bajos y una mayor variabilidad en los valores altos. Esto sugiere la posible presencia de heterocedasticidad (varianza no constante de los residuos), lo que podría afectar la validez de las inferencias realizadas a partir del modelo.





Histograma de los residuos

```{r}
# 2. Histograma de los residuos
hist(residuos,
     main = "Histograma de Residuos",
     xlab = "Residuos",
     col = "lightblue", border = "black")
```

El histograma permite analizar la distribución de los residuos. En este caso, la distribución no es completamente simétrica ni normal, pues presenta cierta asimetría y una posible concentración alrededor de cero. Esto indica que los errores no siguen una distribución normal.



QQ-Plot de residuos

```{r}
# 3. QQ-Plot de residuos
qqnorm(residuos, main = "QQ-Plot de los Residuos")
qqline(residuos, col = "red", lwd = 2)
```


El gráfico de QQ-Plot compara los cuantiles de los residuos con los cuantiles de una distribución normal teórica. Se observa que los puntos no siguen completamente la línea roja, especialmente en los extremos, lo que indica la presencia de colas más pesadas de lo esperado bajo una distribución normal. Esto confirma la posible desviación de la normalidad en los residuos.



Pruebas de normalidad de los residuos

```{r}
# 4. Pruebas de normalidad de los residuos
shapiro_test <- shapiro.test(residuos)
cat("Prueba de Shapiro-Wilk para normalidad de los residuos:\n")
print(shapiro_test)
```

La prueba de Shapiro-Wilk fue aplicada a los residuos del modelo para evaluar si siguen una distribución normal. Los resultados obtenidos son:

  + Estadístico W = 0.78432
  + p-valor < 2.2e-16
  
Dado que el p-valor es significativamente menor a 0.05, se rechaza la hipótesis nula de normalidad. Esto confirma que los residuos no siguen una distribución normal, lo que puede afectar la validez de los intervalos de confianza y las pruebas de hipótesis del modelo.


Gráfico de residuos vs. una variable predictora (ejemplo: Page total likes)

```{r}
# Gráfico de residuos vs. like
plot(train_clean$like, residuos,
     main = "Residuos vs Like",
     xlab = "Like",
     ylab = "Residuos",
     pch = 19, col = "purple")
abline(h = 0, col = "red", lwd = 2)
```


Este gráfico permite evaluar la relación entre los residuos y la variable predictora "Like". Se observa que los residuos no están distribuidos aleatoriamente, sino que presentan un patrón en forma de abanico, lo que nuevamente sugiere heterocedasticidad. La varianza de los residuos parece aumentar a medida que crecen los valores de "Like", lo que podría indicar que la relación entre las variables no es completamente lineal o que existe una influencia de valores atípicos.


**5: Diagnóstico del modelo**

Prueba de homocedasticidad (Breusch-Pagan)

```{r}

# 2. Prueba de homocedasticidad (Breusch-Pagan)
library(lmtest)
breusch_pagan <- bptest(modelo)
cat("\nPrueba de Breusch-Pagan para homocedasticidad:\n")
print(breusch_pagan)

```



Prueba de autocorrelación (Durbin-Watson)

```{r}

# 3. Estadística Durbin-Watson para autocorrelación de los residuos
durbin_watson <- dwtest(modelo)
cat("\nPrueba de Durbin-Watson para autocorrelación de los residuos:\n")
print(durbin_watson)
```



**Paso 6: Leverage y observaciones influyentes**

```{r}
# Calcular leverage
leverage <- hatvalues(modelo)

# Umbral para leverage alto
p <- length(coef(modelo))  # Número de parámetros (incluyendo el intercepto)
n <- nrow(train)  # Número de observaciones
leverage_threshold <- 2 * p / n

# Identificar observaciones con leverage alto
leverage_high <- which(leverage > leverage_threshold)

# Resultados
cat("Valores de leverage:\n")
print(leverage)
cat("\nUmbral para leverage alto:", leverage_threshold, "\n")
cat("\nObservaciones con leverage alto (si las hay):\n")
print(leverage_high)


```

```{r}
# Gráfico de leverage
plot(leverage, 
     main = "Leverage de las Observaciones",
     xlab = "Índice de Observación",
     ylab = "Leverage",
     pch = 19, col = "blue", ylim=c(min(leverage)*.9,max(leverage)*1.05))
abline(h = leverage_threshold, col = "red", lwd = 2, lty = 2)  # Línea del umbral
text(leverage_high, leverage[leverage_high], labels = leverage_high, pos = 3, col = "red")
```



**Paso 7: Distancia de Cook, DFBETAS y DFFITS**

```{r}

# 1. Calcular Distancia de Cook
cooks_distance <- cooks.distance(modelo)

# 2. Calcular DFBETAS
dfbetas_values <- dfbetas(modelo)

# 3. Calcular DFFITS
dffits_values <- dffits(modelo)

# Umbrales sugeridos
cooks_threshold <- 4 / n  # Umbral para Distancia de Cook
dffits_threshold <- 2 * sqrt(p / n)  # Umbral para DFFITS

# Resultados
cat("Distancia de Cook (primeras 10 observaciones):\n")
print(head(cooks_distance, 10))
cat("\nObservaciones con Distancia de Cook alta (> ", cooks_threshold, "):\n")
print(which(cooks_distance > cooks_threshold))
cat("\nDFBETAS (primeras 10 observaciones):\n")
print(head(dfbetas_values, 10))
cat("\nDFFITS (primeras 10 observaciones):\n")
print(head(dffits_values, 10))
cat("\nObservaciones con DFFITS alto (> ", dffits_threshold, "):\n")
print(which(abs(dffits_values) > dffits_threshold))
```

Graficar Distancia de Cook

```{r}
# Graficar Distancia de Cook
plot(cooks_distance,
     main = "Distancia de Cook",
     xlab = "Índice de Observación",
     ylab = "Distancia de Cook",
     pch = 19, col = "blue", ylim=c(min(cooks_distance)*.9,max(cooks_distance)*1.05))
abline(h = cooks_threshold, col = "red", lwd = 2, lty = 2)
text(which(cooks_distance > cooks_threshold), cooks_distance[cooks_distance > cooks_threshold],
     labels = which(cooks_distance > cooks_threshold), pos = 3, col = "red")

```



Graficar DFFITS

```{r}
# Graficar DFFITS
plot(dffits_values,
     main = "DFFITS",
     xlab = "Índice de Observación",
     ylab = "DFFITS",
     pch = 19, col = "green", ylim=c(min(dffits_values)*.85,max(dffits_values)*1.07))
abline(h = c(dffits_threshold, -dffits_threshold), col = "red", lwd = 2, lty = 2)
text(which(abs(dffits_values) > dffits_threshold), dffits_values[abs(dffits_values) > dffits_threshold],
     labels = which(abs(dffits_values) > dffits_threshold), pos = 3, col = "red")

```



# Regresión lineal simple
like

# Regresión lineal múltiple
todas


#Modelo explicativo 
Todas menos share, comment y like

# Modelo predictivo
con share, comment y like
