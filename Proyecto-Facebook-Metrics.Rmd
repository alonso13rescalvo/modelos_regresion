---
title: "Proyecto-Facebook-Metrics"
author: "Cristina, Lucia, Alonso"
date: "2025-02-09"
output: 
  html_document:
      theme: journal
      toc: yes
      toc_depth: 6
      toc_float: yes
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Cargamos las librerias que vamos necesitando a lo largo del codigo

```

```{r}

library(ggplot2)

```

# Introducción

**Información de los autores** Este proyecto ha sido realizado por el grupo 9 del grado de Ciencia e Ingeniería de datos para la asignatura de Modelos de Regresión que cuanta con los siguientes integrantes:

-   **Cristina Rodríguez Ayllón**
-   **Lucía Arnaldo Cuevas**
-   **Alonso Rescalvo Casas**

Nuestro datasetes es el de "Facebook Metrics Dataset".
Es un conjunto de datos que recopila diversas métricas relacionadas con la interacción de los usuarios en páginas de Facebook.
Estas métricas incluyen información sobre impresiones, alcance, interacciones con publicaciones, entre otras.

```{r lectura, warning=FALSE}
# lectura de datos en csv
dataset_Facebook<-read.csv("datos/dataset_Facebook.csv")
# Cambiamos el nombre de las variables 

#datos<-read.csv("datos/datos.csv")
ntotal <- dim(dataset_Facebook)[1] # numero de observaciones
ptotal <- dim(dataset_Facebook)[2] # numero de columnas



```

Comprobamos que tenemos $n=$`r ntotal` observaciones y $p=$`r ptotal` variables en la base de datos.

Según la descripción oficial de los datos, las variables que conforman el conjunto de datos son:

(aqui iria da descripcion de las varibles y tal, la tablita que hizo Alonso)

# EDA

## Preguntas a resolver pre-EDA

(preguntas alonso)

**Variable objetivo: ¿Existe una variable de "respuesta"? ¿Binaria o multiclase?** Sí, la variable de respuesta es "Total Interactions".
Como estamos en un proyecto de regresión, esta variable es numérica continua y no es binaria ni multiclase.

**¿Es posible identificar variables irrelevantes?. Estudiar variables relevantes requiere, habitualmente, métodos estadísticos.** Sí, pero para hacerlo correctamente hay que aplicar métodos estadísticos como matrices de correlación.

**¿Es posible identificar la distribución que siguen las variables?** Sí, se puede hacer con gráficos y pruebas estadísticas como: + Histogramas para visualizar la forma de la distribución.
+ Boxplots para detectar outliers y asimetrías.
+ Q-Q Plots para comparar con una distribución normal.
+ Pruebas estadísticas como Shapiro-Wilk o Kolmogorov-Smirnov para evaluar normalidad.

(preguntas lucía)

## Partición de los datos

Realizamos la división de nuestros datos en 3 muestras: entrenamiento, validación y test.

```{r particion}
# mediante una semilla conseguimos que el ejercicio sea reproducible
set.seed(1)


# creamos índices
indices <- 1:ntotal
ntrain <- ntotal * .5
ntest <- ntotal * .25
nval <- ntotal - (ntrain+ntest)
indices.train <- sample(indices, ntrain, replace = FALSE)
indices.test <- sample(indices[-indices.train],ntest,replace=FALSE)
indices.val <- indices[-c(indices.train,indices.test)]

# Usamos el 50% de la base de datos como conjunto de entrenamiento
# 25% para test
# 25% para validación
train  <- dataset_Facebook[indices.train, ]
test   <- dataset_Facebook[indices.test, ]
val   <- dataset_Facebook[indices.val, ]

```

## Estudio de las variables

La idea es que vayamos viendo que distribucion sigue cada variables (con un histograma), si hay valores atipicos (con un boxplot) y enfrentarlas con el target



### Target

**Total Interactions**

```{r}

summary(train$`Total Interactions`)


```

```{r}
library(ggplot2)
ggplot(train, aes(x = `Total Interactions`)) +
  geom_histogram(binwidth = 50, fill = "lightblue", color = "black") +
  theme_minimal() +
  labs(title = "Distribución del Target (Total Interactions)", x = "Total Interactions", y = "Frecuencia")

```


```{r}
ggplot(train, aes(y = `Total Interactions`)) +
  geom_boxplot(fill = "lightblue", color = "black", outlier.colour = "red") +
  theme_minimal() +
  labs(title = "Boxplot del Target (Total Interactions)", y = "Total Interactions")

```

```{r}
Q1 <- quantile(train$`Total Interactions`, 0.25)
Q3 <- quantile(train$`Total Interactions`, 0.75)
IQR <- Q3 - Q1
limite_inferior <- Q1 - 1.5 * IQR
limite_superior <- Q3 + 1.5 * IQR

outliers <- train %>%
  filter(`Total Interactions` < limite_inferior | `Total Interactions` > limite_superior)

print(outliers)  # Muestra los valores atípicos

```


```{r}
cor_matrix <- cor(train[, c("Total Interactions", "Page total likes", "Lifetime Post Total Reach",
                            "Lifetime Post Total Impressions")], use = "complete.obs")
print(cor_matrix)

```

```{r}
# Instalar y cargar pheatmap (si no lo tienes)
#install.packages("pheatmap")
library(pheatmap)

# Seleccionar solo variables numéricas
numeric_vars <- train[, sapply(train, is.numeric)]

# Calcular la matriz de correlación
cor_matrix <- cor(numeric_vars, use = "complete.obs")

# Renombrar las variables con nombres más cortos
colnames(cor_matrix) <- c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18")  # Edita según tus variables
rownames(cor_matrix) <- colnames(cor_matrix)  # Para que las filas tengan el mismo nombre

# Crear heatmap con nombres cortos
pheatmap(cor_matrix, display_numbers = TRUE, 
         color = colorRampPalette(c("cadetblue1", "mediumpurple1", "pink1"))(50))



```




### Variables

**Page total likes**

```{r}

summary(train$`Page total likes`)

```


```{r}


# Histograma de "Page total likes" en el conjunto de entrenamiento
ggplot(train, aes(x = train$`Page total likes`)) + 
  geom_histogram(binwidth = 500, fill = "lightblue", color = "black", alpha = 0.7) + 
  theme_minimal() +
  labs(title = "Distribución de Page total likes (Train)", x = "Page total likes", y = "Frecuencia")


```


```{r}
# Boxplot de "Page total likes" en el conjunto de entrenamiento
ggplot(train, aes(y = train$`Page total likes`)) + 
  geom_boxplot(fill = "lightblue", color = "black", outlier.colour = "red", outlier.size = 2) +
  theme_minimal() +
  labs(title = "Boxplot de Page total likes (Train)", y = "Page total likes")

```

```{r}
# Cargar librerías necesarias
library(ggplot2)

#  Page total likes
cor(train$`Total Interactions`, train$`Page total likes`, use="complete.obs")  # Correlación
plot(train$`Page total likes`, train$`Total Interactions`, 
     main="Page Total Likes vs Total Interactions",
     xlab="Page Total Likes", ylab="Total Interactions", 
     col="red", pch=16)
```




```{r}
trainmod <- train %>%
  mutate(Page_total_likes_group = cut(`Page total likes`, breaks = 5))  # Agrupamos en intervalos

tabla_frecuencias_likes <- trainmod %>%
  count(Page_total_likes_group) %>%
  mutate(f = n / nrow(train),
         N = cumsum(n),
         F = cumsum(f))
knitr::kable(tabla_frecuencias_likes, digits = 4)

```

**Type**



```{r}
summary(train$`Type`) 

```

```{r}
table(train$Type)


```


```{r}
#  Type (Gráfico de cajas ya que es una variable categórica)
ggplot(train, aes(x = Type, y = `Total Interactions`, fill = Type)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Total Interactions por Type", 
       x = "Type", y = "Total Interactions")


```

```{r}
tabla_frecuencias_type <- trainmod %>%
  count(Type) %>%
  mutate(f = n / nrow(train),
         N = cumsum(n),
         F = cumsum(f))

knitr::kable(tabla_frecuencias_type, digits = 4)

```

**Category**

```{r}
summary(train$Category)
table(train$Category)

```


```{r}



# Histograma de "Page total likes" en el conjunto de entrenamiento
ggplot(train, aes(x = train$Category)) + 
  geom_histogram(binwidth = 500, fill = "lightblue", color = "black", alpha = 0.7) + 
  theme_minimal() +
  labs(title = "Distribución de Page total likes (Train)", x = "Page total likes", y = "Frecuencia")



#  Category (Gráfico de cajas)
ggplot(train, aes(x = as.factor(Category), y = `Total Interactions`, fill = as.factor(Category))) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Total Interactions por Category", 
       x = "Category", y = "Total Interactions")
```



```{r}
# Boxplot de "Page total likes" en el conjunto de entrenamiento
ggplot(train, aes(y = train$Category)) + 
  geom_boxplot(fill = "lightblue", color = "black", outlier.colour = "red", outlier.size = 2) +
  theme_minimal() +
  labs(title = "Boxplot de Page total likes (Train)", y = "Page total likes")

```

```{r}
tabla_frecuencias_category <- trainmod %>%
  count(Category) %>%
  mutate(f = n / nrow(train),
         N = cumsum(n),
         F = cumsum(f))

knitr::kable(tabla_frecuencias_category, digits = 4)

```


**Post Month**


```{r}
summary(train$`Post Month`)

```

```{r}
#  Post Month (Gráfico de cajas)
ggplot(train, aes(x = as.factor(`Post Month`), y = `Total Interactions`, fill = as.factor(`Post Month`))) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Total Interactions por Post Month", 
       x = "Post Month", y = "Total Interactions")
```

```{r}
tabla_frecuencias_month <- trainmod %>%
  count(`Post Month`) %>%
  mutate(f = n / nrow(train),
         N = cumsum(n),
         F = cumsum(f))

knitr::kable(tabla_frecuencias_month, digits = 4)
```


**Post Weekday**


```{r}
summary(train$`Post Weekday`)

```



```{r}
#  Post Weekday (Gráfico de cajas)
ggplot(train, aes(x = as.factor(`Post Weekday`), y = `Total Interactions`, fill = as.factor(`Post Weekday`))) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Total Interactions por Post Weekday", 
       x = "Post Weekday", y = "Total Interactions")


```

```{r}
tabla_frecuencias_weekday <- trainmod %>%
  count(`Post Weekday`) %>%
  mutate(f = n / nrow(train),
         N = cumsum(n),
         F = cumsum(f))
knitr::kable(tabla_frecuencias_weekday, digits = 4)

```

**Post Hour**


```{r}
summary(train$`Post Hour`)

```




```{r}
#  Post Hour (Gráfico de cajas)
ggplot(train, aes(x = as.factor(`Post Hour`), y = `Total Interactions`, fill = as.factor(`Post Hour`))) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Total Interactions por Post Hour", 
       x = "Post Hour", y = "Total Interactions")
```


```{r}
tabla_frecuencias_hour <- trainmod %>%
  count(`Post Hour`) %>%
  mutate(f = n / nrow(train),
         N = cumsum(n),
         F = cumsum(f))

knitr::kable(tabla_frecuencias_hour, digits = 4)
```

**Paid**

**Lifetime Post Total Reach**

**Lifetime Post Total Impressions**

**Lifetime Engaged Users**

**Lifetime Post Consumers**

**Lifetime Post Consumptions**

**Lifetime Post Impressions by people who have liked your Page**

**Lifetime Post reach by people who like your Page**

**Lifetime People who have liked your Page and engaged with your post**

**Comment**

**Like**

**Share**




# Regresión lineal simple


```{r}
# Eliminar filas con valores faltantes en cualquier columna
train_clean <- na.omit(train)

# Verificar que no hay valores faltantes después de la limpieza
colSums(is.na(train_clean))
```


**1: Ajustar el modelo de regresión lineal**

```{r}
# Ajustar el modelo de regresión lineal
modelo <- lm(`Total Interactions` ~ `Page total likes` + Type + Category + `Post Month` + 
             `Post Weekday` + `Post Hour` + Paid + `Lifetime Post Total Reach` + 
             `Lifetime Post Total Impressions` + `Lifetime Engaged Users` + 
             `Lifetime Post Consumers` + `Lifetime Post Consumptions` + 
             `Lifetime Post Impressions by people who have liked your Page` + 
             `Lifetime Post reach by people who like your Page` + 
             `Lifetime People who have liked your Page and engaged with your post` + 
             comment + like + share, data = train_clean)

# Obtener estimadores de los parámetros y errores estándar
estimadores <- coef(summary(modelo))  # Incluye estimadores y errores estándar

# Imprimir los resultados
cat("Estimadores para los parámetros del modelo:\n")
print(estimadores)
```


**2: Resumen del modelo**

```{r}
# Obtener resumen del modelo
summary(modelo)
```


**3: Tabla ANOVA**

```{r}
# Obtener y mostrar la tabla ANOVA
tabla_anova <- anova(modelo)
cat("\nTabla ANOVA:\n")
print(tabla_anova)
```


**4: Estudiar los residuos**

Gráfico de residuos vs. valores ajustados

```{r}
# Obtener los residuos
residuos <- resid(modelo)

# 1. Gráfico de residuos vs. valores ajustados
valores_ajustados <- fitted(modelo)
plot(valores_ajustados, residuos,
     main = "Residuos vs Valores Ajustados",
     xlab = "Valores Ajustados",
     ylab = "Residuos",
     pch = 19, col = "blue")
abline(h = 0, col = "red", lwd = 2)
```

Histograma de los residuos

```{r}
# 2. Histograma de los residuos
hist(residuos,
     main = "Histograma de Residuos",
     xlab = "Residuos",
     col = "lightblue", border = "black")
```

QQ-Plot de residuos

```{r}
# 3. QQ-Plot de residuos
qqnorm(residuos, main = "QQ-Plot de los Residuos")
qqline(residuos, col = "red", lwd = 2)
```

Pruebas de normalidad de los residuos

```{r}
# 4. Pruebas de normalidad de los residuos
shapiro_test <- shapiro.test(residuos)
cat("Prueba de Shapiro-Wilk para normalidad de los residuos:\n")
print(shapiro_test)
```

Gráfico de residuos vs. una variable predictora (ejemplo: Page total likes)

```{r}
# Gráfico de residuos vs. like
plot(train_clean$like, residuos,
     main = "Residuos vs Like",
     xlab = "Like",
     ylab = "Residuos",
     pch = 19, col = "purple")
abline(h = 0, col = "red", lwd = 2)
```


**5: Diagnóstico del modelo**

```{r}

```





# Regresión lineal múltiple





