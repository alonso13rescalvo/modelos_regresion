---
title: "Proyecto-Facebook-Metrics"
author: "Cristina, Lucia, Alonso"
date: "2025-02-09"
output: 
  html_document:
      theme: journal
      toc: yes
      toc_depth: 6
      toc_float: yes
editor_options: 
  markdown: 
    wrap: sentence
---
```{r}

library(ggplot2)
library(dplyr)
library(knitr)
#library(gt)
library(pheatmap)

```

# Introducción (Cristina)

**Información de los autores** Este proyecto ha sido realizado por el grupo 9 del grado de Ciencia e Ingeniería de datos para la asignatura de Modelos de Regresión que cuenta con los siguientes integrantes:

-   **Cristina Rodríguez Ayllón**
-   **Lucía Arnaldo Cuevas**
-   **Alonso Rescalvo Casas**

Nuestro datasetes es el de "Facebook Metrics Dataset". Es un conjunto de datos que recopila diversas métricas relacionadas con la interacción de los usuarios en páginas de Facebook. Estas métricas incluyen información sobre impresiones, alcance, interacciones con publicaciones, entre otras.

```{r lectura, warning=FALSE}
# lectura de datos en csv
#dataset_Facebook <- read.csv("datos/dataset_Facebook.csv", stringsAsFactors = FALSE)
# Cambiamos el nombre de las variables 

library(readr)
dataset_Facebook <- read_delim("dataset_Facebook.csv", 
    delim = ";", escape_double = FALSE, trim_ws = TRUE)


#datos<-read.csv("datos/datos.csv")
ntotal <- dim(dataset_Facebook)[1] # numero de observaciones
ptotal <- dim(dataset_Facebook)[2] # numero de columnas



```

Comprobamos que tenemos $n=$`r ntotal` observaciones y $p=$`r ptotal` variables en la base de datos.

Según la descripción oficial de los datos, las variables que conforman el conjunto de datos son:

-   **Page total likes** (numérica) → Total de "Me gusta" de la página en el momento de la publicación.
-   **Type** (categórica) → Tipo de publicación (Photo, Status, Link, Video).
-   **Category** (categórica - numérica) → Categoría de la publicación (1, 2, 3).
-   **Post Month** (numérica - discreta) → Mes en que se publicó el post.
-   **Post Weekday** (numérica - discreta) → Día de la semana en que se publicó (1 = Lunes, ..., 7 = Domingo).
-   **Post Hour** (numérica - discreta) → Hora de la publicación.
-   **Paid** (categórica - binaria) → Si la publicación fue promocionada (1 = Sí, 0 = No).
-   **Lifetime Post Total Reach** (numérica - continua) → Número de personas alcanzadas.
-   **Lifetime Post Total Impressions** (numérica - continua) → Número de impresiones totales.
-   **Lifetime Engaged Users** (numérica - continua) → Número de personas que interactuaron con la publicación.
-   **Lifetime Post Consumers** (numérica - continua) → Número de personas que consumieron el contenido.
-   **Lifetime Post Consumptions** (numérica - continua) → Número de interacciones con el contenido.
-   **Lifetime Post Impressions by people who have liked your Page** (numérica - continua) → Impresiones de personas que han dado "Me gusta" a la página.
-   **Lifetime Post reach by people who like your Page** (numérica - continua) → Alcance de personas que han dado "Me gusta" a la página.
-   **Lifetime People who have liked your Page and engaged with your post** (numérica - continua) → Personas que han dado "Me gusta" a la página y han interactuado con la publicación.
-   **comment** (numérica - discreta) → Número de comentarios en la publicación.
-   **like** (numérica - discreta) → Número de "Me gusta" en la publicación.
-   **share** (numérica - discreta) → Número de veces compartido.
-   **Total Interactions** (numérica - discreta) → Suma de comment, like y share.



# EDA

## Preguntas a resolver pre-EDA

(preguntas alonso)

**Variable objetivo: ¿Existe una variable de "respuesta"? ¿Binaria o multiclase?** (Cristina)
Sí, la variable de respuesta es "Total Interactions". Como estamos en un proyecto de regresión, esta variable es numérica continua y no es binaria ni multiclase.

**¿Es posible identificar variables irrelevantes?. Estudiar variables relevantes requiere, habitualmente, métodos estadísticos.** (Cristina)
Sí, pero para hacerlo correctamente hay que aplicar métodos estadísticos como matrices de correlación.

**¿Es posible identificar la distribución que siguen las variables?** (Cristina)
Sí, se puede hacer con gráficos y pruebas estadísticas como: + Histogramas para visualizar la forma de la distribución. + Boxplots para detectar outliers y asimetrías. + Q-Q Plots para comparar con una distribución normal. + Pruebas estadísticas como Shapiro-Wilk o Kolmogorov-Smirnov para evaluar normalidad.

(preguntas lucía)

## Partición de los datos (Cristina)

Realizamos la división de nuestros datos en 3 muestras: entrenamiento, validación y test.

```{r particion}
# mediante una semilla conseguimos que el ejercicio sea reproducible
set.seed(1)


# creamos índices
indices <- 1:ntotal
ntrain <- ntotal * .5
ntest <- ntotal * .25
nval <- ntotal - (ntrain+ntest)
indices.train <- sample(indices, ntrain, replace = FALSE)
indices.test <- sample(indices[-indices.train],ntest,replace=FALSE)
indices.val <- indices[-c(indices.train,indices.test)]

# Usamos el 50% de la base de datos como conjunto de entrenamiento
# 25% para test
# 25% para validación
train <- dataset_Facebook[indices.train,]
test  <- dataset_Facebook[indices.test,]
val   <- dataset_Facebook[indices.val, ]


```

## Estudio de las variables

La idea es que vayamos viendo que distribucion sigue cada variables (con un histograma), si hay valores atipicos (con un boxplot) y enfrentarlas con el target

### Target (Cristina)

**Total Interactions**
Nuestro target es el total de interacciones, que es la suma de “me gusta”, “comentarios” y “compartir” de la publicación.

```{r}

summary(train$`Total Interactions`)


```

```{r}
#Histograma(Para ver la forma de la distribución):

library(ggplot2)
ggplot(train, aes(x = `Total Interactions`)) +
  geom_histogram(binwidth = 50, fill = "lightblue", color = "black") +
  theme_minimal() +
  labs(title = "Distribución del Target (Total Interactions)", x = "Total Interactions", y = "Frecuencia")

```

```{r}
#Boxplot(Para detectar outliers):

ggplot(train, aes(y = `Total Interactions`)) +
  geom_boxplot(fill = "lightblue", color = "black", outlier.colour = "red") +
  theme_minimal() +
  labs(title = "Boxplot del Target (Total Interactions)", y = "Total Interactions")
```

```{r}
# Seleccionar solo variables numéricas
numeric_vars <- train[, sapply(train, is.numeric)]

# Calcular la matriz de correlación
cor_matrix <- cor(numeric_vars, use = "complete.obs")

# Renombrar las variables con nombres más cortos
colnames(cor_matrix) <- c("1", "2", "3", "4","5", "6", "7", "8","9", "10", "11", "12","13", "14", "15", "16", "17", "18" )  # Edita según tus variables
rownames(cor_matrix) <- colnames(cor_matrix)  # Para que las filas tengan el mismo nombre

# Crear heatmap con nombres cortos
pheatmap(cor_matrix, display_numbers = TRUE, 
         color = colorRampPalette(c("#98F5FF", "white", "#AB82FF"))(50))

```

### Variables

**Page total likes** (Cristina)
Esta variable (Total de "me gusta" de la página) esvel número de personas a las que les ha gustado la página de la empresa.

```{r}

summary(train$`Page total likes`)

```

El análisis de la variable Page total likes muestra que los valores oscilan entre un mínimo de 81,370 y un máximo de 139,441. La mediana se sitúa en 128,032, mientras que la media es ligeramente menor, con un valor de 122,570, lo que sugiere una leve asimetría hacia la izquierda. Esto indica que la mayoría de las publicaciones tienen un número de likes relativamente alto, concentrándose entre los valores de 120,000 y 140,000, aunque existen algunas con menos de 100,000 likes.

```{r}
# Histograma de "Page total likes" en el conjunto de entrenamiento
ggplot(train, aes(x = train$`Page total likes`)) + 
  geom_histogram(binwidth = 400, fill = "lightblue", color = "black", alpha = 0.7) + 
  theme_minimal() +
  labs(title = "Distribución de Page total likes (Train)", x = "Page total likes", y = "Frecuencia")

```

Al observar el histograma, se aprecia que la distribución de los likes no es completamente uniforme, sino que tiende a agruparse en los valores más elevados.

```{r}
# Boxplot de "Page total likes" en el conjunto de entrenamiento
ggplot(train, aes(y = train$`Page total likes`)) + 
  geom_boxplot(fill = "lightblue", color = "black", outlier.colour = "red", outlier.size = 2) +
  theme_minimal() +
  labs(title = "Boxplot de Page total likes (Train)", y = "Page total likes")

```

El boxplot refuerza esta idea, mostrando que la mayor parte de los datos se encuentra dentro de un rango definido, sin valores extremos que se consideren atípicos.

```{r}
# Cargar librerías necesarias
library(ggplot2)

#  Page total likes
cor(train$`Total Interactions`, train$`Page total likes`, use="complete.obs")  # Correlación
plot(train$`Page total likes`, train$`Total Interactions`, 
     main="Page Total Likes vs Total Interactions",
     xlab="Page Total Likes", ylab="Total Interactions", 
     col="red", pch=16)
```

En cuanto a la relación entre Page total likes y Total Interactions, la correlación obtenida es baja o moderada, lo que indica que el número de likes en una página no determina de manera significativa el nivel de interacción de sus publicaciones. El diagrama de dispersión confirma esta observación, ya que no se percibe una tendencia clara entre ambas variables. Hay casos en los que páginas con un menor número de likes generan una gran cantidad de interacciones, mientras que otras con más likes no necesariamente logran el mismo nivel de engagement.

Esto sugiere que la cantidad de likes en una página no es el único factor que influye en la interacción del público. Es probable que variables como el tipo de publicación, la hora en la que se publica o el contenido del mensaje tengan un impacto mayor en el número de interacciones.



**Type** (Cristina)
En cuanto a ala varible Tipo, se trata del tipo de contenido (Enlace, Foto, Estado, Vídeo).

```{r}
summary(train$`Type`) 

```

```{r}
table(train$Type)


```

```{r}
library(ggplot2)

# Crear un gráfico de barras
ggplot(train, aes(x = Type)) + 
  geom_bar() +
  labs(title = "Gráfico de Barras de la Variable 'type'", 
       x = "Tipo", 
       y = "Frecuencia") +
  theme_minimal()


```

Se puede ver que predominan las fotos ante el resto.



```{r}
# Crear un boxplot para enfrentar la variable categórica con el target
ggplot(train, aes(x = as.factor(Type), y = `Total Interactions`)) +
  geom_boxplot(fill = "skyblue", color = "darkblue") +
  labs(title = "Boxplot: Type vs Total Interactions",
       x = "Type",
       y = "Total Interactions") +
  theme_minimal()

```

Photo parece ser el tipo de contenido más propenso a generar interacciones extremas (outliers).
Esto podría reflejar que las fotos tienen un mayor potencial de viralización.

Video tiene una dispersión más grande en las interacciones, pero menos valores atípicos, lo que podría sugerir un desempeño más uniforme, con publicaciones tanto exitosas como mediocres.

Las publicaciones de tipo Link parecen ser las que generan menos interacciones, con poca variación y pocos outliers.

La mediana de interacciones es similar entre Photo, Status, y Video, pero las fotos destacan por sus outliers hacia arriba.

**Category** (Cristina)
La variable categoría es la caracterización manual de contenido: acción (ofertas especiales y concursos), producto (publicidad directa, contenido explícito relacionado con la marca) e inspiración (contenido no explícito relacionado con la marca).
```{r}
summary(train$Category)
table(train$Category)

```
El 1 reprsenta "Action", el 2 es "Product" y el 3 es "Inspiration". 

```{r}
# Convertir Category en un factor (si no lo es ya)
train$Category <- as.factor(train$Category)

# Crear el gráfico de barras con colores personalizados
ggplot(train, aes(x = Category, fill = Category)) + 
  geom_bar() +
  scale_fill_manual(values = c("#98F5FF", "blue", "darkblue")) +  # Paleta manual
  labs(title = "Gráfico de Barras de la Variable 'Category' con Colores Personalizados", 
       x = "Categoría", 
       y = "Frecuencia") +
  theme_minimal()



```

```{r}

# Crear un boxplot para enfrentar la variable categórica con el target
ggplot(train, aes(x = as.factor(Category), y = `Total Interactions`)) +
  geom_boxplot(fill = "skyblue", color = "darkblue") +
  labs(title = "Boxplot: Category vs Total Interactions",
       x = "Category",
       y = "Total Interactions") +
  theme_minimal()
```





**Post Month** (Cristina)

La variable "Mes del posteo" se trata del mes en que se publicó el post (enero, febrero, marzo,…, diciembre).

```{r}
summary(train$`Post Month`)
table(train$`Post Month`)

```

```{r}
# Crear un gráfico de barras para la variable 'Post Month'
ggplot(train, aes(x = factor(`Post Month`))) + 
  geom_bar(fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "Gráfico de Barras de 'Post Month'", 
       x = "Post Month", 
       y = "Frecuencia") +
  theme_minimal()


```
```{r}
# Crear un boxplot para enfrentar la variable categórica con el target
ggplot(train, aes(x = as.factor(`Post Month`), y = `Total Interactions`)) +
  geom_boxplot(fill = "skyblue", color = "darkblue") +
  labs(title = "Boxplot: Post Month vs Total Interactions",
       x = "Post Month",
       y = "Total Interactions") +
  theme_minimal()
```


Algunos meses muestran una mayor dispersión de interacciones (como en julio y octubre), lo que indica que hubo publicaciones con interacciones muy por encima del promedio.

Se observan outliers en varios meses, lo que sugiere que hubo publicaciones excepcionales con interacciones inusualmente altas.

Los meses 7 (julio) y 10 (octubre) parecen tener la mayor variabilidad en interacciones.

No parece haber una tendencia clara en la estacionalidad de las interacciones a lo largo de los meses.

Algunos meses tienen más publicaciones virales (con valores extremos), pero la mayoría de los meses tienen una distribución de interacciones relativamente baja y estable.


**Post Weekday** (Cristina)
Esta variable trata del día de la semana en que se publicó la entrada (domingo, lunes, …, sábado).
```{r}
summary(train$`Post Weekday`)
table(train$`Post Weekday`)

```

```{r}
# Crear un gráfico de barras para la variable 'Post Month'
ggplot(train, aes(x = factor(`Post Weekday`))) + 
  geom_bar(fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "Gráfico de Barras de `Post Weekday`", 
       x = "Post Weekday", 
       y = "Frecuencia") +
  theme_minimal()


```

```{r}
# Crear un boxplot para enfrentar la variable categórica con el target
ggplot(train, aes(x = as.factor(`Post Weekday`), y = `Total Interactions`)) +
  geom_boxplot(fill = "skyblue", color = "darkblue") +
  labs(title = "Boxplot: Post Weekday vs Total Interactions",
       x = "Post Weekday",
       y = "Total Interactions") +
  theme_minimal()
```

No parece haber una tendencia clara en la estacionalidad de las interacciones a lo largo de la semana.



**Post Hour** (Cristina)

Esta variable es la hora de publicación de la publicación (0, 1, 2, 3, 4, …, 23)

```{r}
summary(train$`Post Hour`)
table(train$`Post Hour`)
```

```{r}
# Crear un gráfico de barras para la variable 'Post Month'
ggplot(train, aes(x = factor(`Post Hour`))) + 
  geom_bar(fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "Gráfico de Barras de `Post Hour`", 
       x = "Post Hour", 
       y = "Frecuencia") +
  theme_minimal()


```
```{r}
# Crear un boxplot para enfrentar la variable categórica con el target
ggplot(train, aes(x = as.factor(`Post Hour`), y = `Total Interactions`)) +
  geom_boxplot(fill = "skyblue", color = "darkblue") +
  labs(title = "Boxplot: Post Hour vs Total Interactions",
       x = "Post Hour",
       y = "Total Interactions") +
  theme_minimal()
```
Los resultados muestran que las publicaciones realizadas entre las 5 AM y 12 PM tienden a generar más interacciones en promedio. En particular, las publicaciones a las 5 AM y 12 PM presentan las medianas más altas, indicando una mayor participación de los usuarios.

Además, se identificaron varios outliers (valores atípicos) en la madrugada (especialmente entre las 2 AM y 5 AM), lo que sugiere que algunas publicaciones pueden volverse virales, aunque no sea la norma. Por otro lado, las publicaciones realizadas después de las 5 PM muestran una menor cantidad de interacciones y una variabilidad reducida.


**Enfrentar las variables con el target**
```{r}
# PAID
cor(train$`Total Interactions`, train$Paid, use="complete.obs")  # Correlación
plot(train$Paid, train$`Total Interactions`, main="Paid vs Total Interactions",
     xlab="Paid", ylab="Total Interactions", col="purple", pch=16)

# Lifetime Post Total Reach
cor(train$`Total Interactions`, train$`Lifetime Post Total Reach`, use="complete.obs")  # Correlación
plot(train$`Lifetime Post Total Reach`, train$`Total Interactions`, main="Lifetime Post Total Reach vs Total Interactions",
     xlab="Lifetime Post Total Reach", ylab="Total Interactions", col="orange", pch=16)

# Lifetime Post Total Impressions
cor(train$`Total Interactions`, train$`Lifetime Post Total Impressions`, use="complete.obs")  # Correlación
plot(train$`Lifetime Post Total Impressions`, train$`Total Interactions`, main="Lifetime Post Total Impressions vs Total Interactions",
     xlab="Lifetime Post Total Impressions", ylab="Total Interactions", col="brown", pch=16)

# Lifetime Engaged Users
cor(train$`Total Interactions`, train$`Lifetime Engaged Users`, use="complete.obs")  # Correlación
plot(train$`Lifetime Engaged Users`, train$`Total Interactions`, main="Lifetime Engaged Users vs Total Interactions",
     xlab="Lifetime Engaged Users", ylab="Total Interactions", col="cyan", pch=16)

# Lifetime Post Consumers
cor(train$`Total Interactions`, train$`Lifetime Post Consumers`, use="complete.obs")  # Correlación
plot(train$`Lifetime Post Consumers`, train$`Total Interactions`, main="Lifetime Post Consumers vs Total Interactions",
     xlab="Lifetime Post Consumers", ylab="Total Interactions", col="magenta", pch=16)

# Lifetime Post Consumptions
cor(train$`Total Interactions`, train$`Lifetime Post Consumptions`, use="complete.obs")  # Correlación
plot(train$`Lifetime Post Consumptions`, train$`Total Interactions`, main="Lifetime Post Consumptions vs Total Interactions",
     xlab="Lifetime Post Consumptions", ylab="Total Interactions", col="gray", pch=16)
```
**Paid**

**Lifetime Post Total Reach**

**Lifetime Post Total Impressions**

**Lifetime Engaged Users**

**Lifetime Post Consumers**

**Lifetime Post Consumptions**

```{r}
#LIKE
cor(train$`Total Interactions`, train$like, use="complete.obs")  # Correlación
plot(train$like, train$`Total Interactions`, main="Likes vs Total Interactions",
     xlab="Likes", ylab="Total Interactions", col="red", pch=16)


#COMMENT
cor(train$`Total Interactions`, train$comment, use="complete.obs")  # Correlación
plot(train$comment, train$`Total Interactions`, main="comment vs Total Interactions",
     xlab="comment", ylab="Total Interactions", col="blue", pch=16)


#SHARE
cor(train$`Total Interactions`, train$share, use="complete.obs")  # Correlación
plot(train$share, train$`Total Interactions`, main="share vs Total Interactions",
     xlab="share", ylab="Total Interactions", col="yellow", pch=16)


#Lifetime People who have liked your Page and engaged with your post

cor(train$`Total Interactions`, train$`Lifetime People who have liked your Page and engaged with your post`, use="complete.obs")  # Correlación
plot(train$`Lifetime People who have liked your Page and engaged with your post`, train$`Total Interactions`, main="Lifetime People who have liked your Page and engaged with your post vs Total Interactions",
     xlab="Lifetime People who have liked your Page and engaged with your post", ylab="Total Interactions", col="green", pch=16)


#Lifetime Post reach by people who like your Page

cor(train$`Total Interactions`, train$`Lifetime Post reach by people who like your Page`, use="complete.obs")  # Correlación
plot(train$`Lifetime Post reach by people who like your Page`, train$`Total Interactions`, main="`Lifetime Post reach by people who like your Page` vs Total Interactions",
     xlab="`Lifetime Post reach by people who like your Page`", ylab="Total Interactions", col="4157", pch=16)


#Lifetime Post Impressions by people who have liked your Page


cor(train$`Total Interactions`, train$`Lifetime Post Impressions by people who have liked your Page`, use="complete.obs")  # Correlación
plot(train$`Lifetime Post Impressions by people who have liked your Page`, train$`Total Interactions`, main="`Lifetime Post Impressions by people who have liked your Page` vs Total Interactions",
     xlab="`Lifetime Post Impressions by people who have liked your Page`", ylab="Total Interactions", col="5423", pch=16)


```

**Lifetime Post Impressions by people who have liked your Page**

**Lifetime Post reach by people who like your Page**

**Lifetime People who have liked your Page and engaged with your post**

**Comment**

**Like**

**Share**



# Modelos de Regresión lineal

## Regresión lineal simple (Cristina)

Tras observar las variables hemos optado por hacer la regresión lineal simple enfrentando Total Interactions (nuestro target) con la variable Likes.


**1: Ajustar el modelo de regresión lineal**

Ajustamos el modelo: Estamos ajustando un modelo de regresión lineal simple donde la variable dependiente es Total Interactions y la variable predictora es Page total likes. Ajustamos el modelo y calculamos los coeficientes de la recta de regresión.

Obtener estimadores: Extraemos los coeficientes del modelo (intercepto y pendiente) junto con sus errores estándar, valores t y p-valores.

Esto nos permite entender la relación entre Page total likes y Total Interactions.

```{r}
# Ajustar el modelo de regresión lineal
train_clean <- na.omit(train)
modelo <- lm(`Total Interactions` ~ `like`, data = train_clean)

# Obtener estimadores de los parámetros y errores estándar
estimadores <- coef(summary(modelo))  # Incluye estimadores y errores estándar

# Imprimir los resultados
cat("Estimadores para los parámetros del modelo:\n")
print(estimadores)
```

Se ajustó un modelo de regresión lineal simple para analizar la relación entre la variable independiente "Likes" y la variable dependiente "Total Interactions". La ecuación estimada del modelo es la siguiente:

Total_Interactions = 10.96 + 1.124 × like

Los resultados del modelo indican lo siguiente:

-   Intercepto (β_0=10.96): Representa el valor esperado de interacciones totales cuando el número de "likes" es cero.
-   Pendiente (β_1=1.124): Indica que, en promedio, cada "like" adicional se asocia con un incremento de 1.124 interacciones totales.

Para evaluar la significancia de los coeficientes, se analizaron sus respectivos errores estándar, valores t y p-valores.

-   El p-valor asociado a la variable "like" es extremadamente pequeño (3.09×10\^−259), lo que indica que su influencia en el modelo es altamente significativa. Asimismo, su t-valor es considerablemente alto (174.87), lo que refuerza su importancia en la predicción de interacciones totales.

-   Dado que ambos p-valores son menores a 0.05, se concluye que los coeficientes son estadísticamente significativos, lo que valida la relación entre los "likes" y las interacciones totales.

**2: Resumen del modelo**

```{r}
# Obtener resumen del modelo
summary(modelo)
```

**3: Tabla ANOVA**

```{r}
# Obtener y mostrar la tabla ANOVA
tabla_anova <- anova(modelo)
cat("\nTabla ANOVA:\n")
print(tabla_anova)
```

Suma de Cuadrados (Sum Sq): + La variabilidad explicada por la variable "like" en el modelo es 13555096, lo que representa una proporción significativa de la variabilidad total en "Total Interactions". + La variabilidad residual es de 108599, lo que sugiere que la mayor parte de la variabilidad en las interacciones totales es explicada por la variable "like".

Valor F: + El estadístico F = 30580 indica cuántas veces la variabilidad explicada por el modelo es mayor que la variabilidad no explicada. Un valor F tan alto sugiere que el modelo es altamente significativo.

Significancia del Modelo (p-valor): + El p-valor es \< 2.2e-16, lo que es significativamente menor al umbral habitual de 0.05. + Esto indica que existe una relación estadísticamente significativa entre "like" y "Total Interactions", descartando la posibilidad de que la relación observada sea producto del azar.

**4: Estudiar los residuos**

Gráfico de residuos vs. valores ajustados

```{r}
# Obtener los residuos
residuos <- resid(modelo)

# 1. Gráfico de residuos vs. valores ajustados
valores_ajustados <- fitted(modelo)
plot(valores_ajustados, residuos,
     main = "Residuos vs Valores Ajustados",
     xlab = "Valores Ajustados",
     ylab = "Residuos",
     pch = 19, col = "blue")
abline(h = 0, col = "red", lwd = 2)
```

Este gráfico muestra la relación entre los residuos y los valores ajustados por el modelo. Se observa que la dispersión de los puntos no es completamente homogénea, ya que hay una mayor concentración en los valores bajos y una mayor variabilidad en los valores altos. Esto sugiere la posible presencia de heterocedasticidad (varianza no constante de los residuos), lo que podría afectar la validez de las inferencias realizadas a partir del modelo.

Histograma de los residuos

```{r}
# 2. Histograma de los residuos
hist(residuos,
     main = "Histograma de Residuos",
     xlab = "Residuos",
     col = "lightblue", border = "black")
```

El histograma permite analizar la distribución de los residuos. En este caso, la distribución no es completamente simétrica ni normal, pues presenta cierta asimetría y una posible concentración alrededor de cero. Esto indica que los errores no siguen una distribución normal.

QQ-Plot de residuos

```{r}
# 3. QQ-Plot de residuos
qqnorm(residuos, main = "QQ-Plot de los Residuos")
qqline(residuos, col = "red", lwd = 2)
```

El gráfico de QQ-Plot compara los cuantiles de los residuos con los cuantiles de una distribución normal teórica. Se observa que los puntos no siguen completamente la línea roja, especialmente en los extremos, lo que indica la presencia de colas más pesadas de lo esperado bajo una distribución normal. Esto confirma la posible desviación de la normalidad en los residuos.

Pruebas de normalidad de los residuos

```{r}
# 4. Pruebas de normalidad de los residuos
shapiro_test <- shapiro.test(residuos)
cat("Prueba de Shapiro-Wilk para normalidad de los residuos:\n")
print(shapiro_test)
```

La prueba de Shapiro-Wilk fue aplicada a los residuos del modelo para evaluar si siguen una distribución normal. Los resultados obtenidos son:

-   Estadístico W = 0.78432
-   p-valor \< 2.2e-16

Dado que el p-valor es significativamente menor a 0.05, se rechaza la hipótesis nula de normalidad. Esto confirma que los residuos no siguen una distribución normal, lo que puede afectar la validez de los intervalos de confianza y las pruebas de hipótesis del modelo.

Gráfico de residuos vs. una variable predictora (ejemplo: Page total likes)

```{r}
# Gráfico de residuos vs. like
plot(train_clean$like, residuos,
     main = "Residuos vs Like",
     xlab = "Like",
     ylab = "Residuos",
     pch = 19, col = "purple")
abline(h = 0, col = "red", lwd = 2)
```

Este gráfico permite evaluar la relación entre los residuos y la variable predictora "Like". Se observa que los residuos no están distribuidos aleatoriamente, sino que presentan un patrón en forma de abanico, lo que nuevamente sugiere heterocedasticidad. La varianza de los residuos parece aumentar a medida que crecen los valores de "Like", lo que podría indicar que la relación entre las variables no es completamente lineal o que existe una influencia de valores atípicos.

**5: Diagnóstico del modelo**

Prueba de homocedasticidad (Breusch-Pagan)

```{r}

# 2. Prueba de homocedasticidad (Breusch-Pagan)
library(lmtest)
breusch_pagan <- bptest(modelo)
cat("\nPrueba de Breusch-Pagan para homocedasticidad:\n")
print(breusch_pagan)

```

La prueba de Breusch-Pagan se utiliza para evaluar si los residuos del modelo tienen varianza constante (homocedasticidad) o si, por el contrario, presentan heterocedasticidad (varianza no constante).

Resultados obtenidos: + Estadístico BP = 128.12 + Grados de libertad (df) = 1 + p-valor \< 2.2e-16 Interpretación:

-   El p-valor es extremadamente pequeño (\< 0.05), lo que indica que se rechaza la hipótesis nula de homocedasticidad.
-   Esto significa que existe heterocedasticidad en los residuos, es decir, la varianza de los errores no es constante a lo largo de los valores de la variable predictora.

Prueba de autocorrelación (Durbin-Watson)

```{r}

# 3. Estadística Durbin-Watson para autocorrelación de los residuos
durbin_watson <- dwtest(modelo)
cat("\nPrueba de Durbin-Watson para autocorrelación de los residuos:\n")
print(durbin_watson)
```

La prueba de Durbin-Watson se emplea para detectar la presencia de autocorrelación en los residuos, es decir, si los errores están correlacionados en función del orden de las observaciones.

Resultados obtenidos:

-   Estadístico DW = 1.7823
-   p-valor = 0.04265
-   Hipótesis alternativa: Existe autocorrelación positiva en los residuos. Interpretación:

El estadístico Durbin-Watson cercano a 2 indica que no hay una autocorrelación fuerte. Sin embargo, el p-valor de 0.04265 es menor a 0.05, lo que sugiere la presencia de una autocorrelación positiva débil en los residuos. La autocorrelación de los errores puede indicar que hay una relación no capturada en el modelo o que las observaciones no son completamente independientes.

**Paso 6: Leverage y observaciones influyentes**

```{r}
# Calcular leverage
leverage <- hatvalues(modelo)

# Umbral para leverage alto
p <- length(coef(modelo))  # Número de parámetros (incluyendo el intercepto)
n <- nrow(train)  # Número de observaciones
leverage_threshold <- 2 * p / n

# Identificar observaciones con leverage alto
leverage_high <- which(leverage > leverage_threshold)

# Resultados
cat("Valores de leverage:\n")
print(leverage)
cat("\nUmbral para leverage alto:", leverage_threshold, "\n")
cat("\nObservaciones con leverage alto (si las hay):\n")
print(leverage_high)


```

Se calculó el umbral para identificar leverage alto como: 0.016 e identificaron 14 observaciones que superan el umbral de leverage alto. Estas observaciones son: 1,18,70,84,95,115,146,170,177,183,191,205,219,240 En el gráfico de leverage, estas observaciones están señalizadas con el núemro en rojo.

```{r}
# Gráfico de leverage
plot(leverage, 
     main = "Leverage de las Observaciones",
     xlab = "Índice de Observación",
     ylab = "Leverage",
     pch = 19, col = "blue", ylim=c(min(leverage)*.9,max(leverage)*1.05))
abline(h = leverage_threshold, col = "red", lwd = 2, lty = 2)  # Línea del umbral
text(leverage_high, leverage[leverage_high], labels = leverage_high, pos = 3, col = "red")
```

**Paso 7: Distancia de Cook, DFBETAS y DFFITS**

```{r}

# 1. Calcular Distancia de Cook
cooks_distance <- cooks.distance(modelo)

# 2. Calcular DFBETAS
dfbetas_values <- dfbetas(modelo)

# 3. Calcular DFFITS
dffits_values <- dffits(modelo)

# Umbrales sugeridos
cooks_threshold <- 4 / n  # Umbral para Distancia de Cook
dffits_threshold <- 2 * sqrt(p / n)  # Umbral para DFFITS

# Resultados
cat("Distancia de Cook (primeras 10 observaciones):\n")
print(head(cooks_distance, 10))
cat("\nObservaciones con Distancia de Cook alta (> ", cooks_threshold, "):\n")
print(which(cooks_distance > cooks_threshold))
cat("\nDFBETAS (primeras 10 observaciones):\n")
print(head(dfbetas_values, 10))
cat("\nDFFITS (primeras 10 observaciones):\n")
print(head(dffits_values, 10))
cat("\nObservaciones con DFFITS alto (> ", dffits_threshold, "):\n")
print(which(abs(dffits_values) > dffits_threshold))
```

Observaciones con Distancia de Cook alta: 1,11,30,31,67,70,95,115,128,183,191,204,205,209,219 Estas observaciones tienen una influencia significativa en el modelo. En el gráfico, las observaciones destacadas en rojo superan el umbral y podrían estar afectando los coeficientes de la regresión.

Observaciones con DFFITS alto: 1,11,30,31,67,70,95,115,128,183,191,204,205,209,219 Estas observaciones tienen un gran impacto en la predicción individual de la variable dependiente. En el gráfico, las observaciones con valores extremos de DFFITS están resaltadas en rojo.

Los valores de DFBETAS indican que algunas observaciones tienen un impacto significativo en los coeficientes del modelo. En particular:la observación 1 tiene un DFBETAS alto en el intercepto y la variable "like", lo que indica que al removerla, los coeficientes cambiarían notablemente.

Graficar Distancia de Cook

```{r}
# Graficar Distancia de Cook
plot(cooks_distance,
     main = "Distancia de Cook",
     xlab = "Índice de Observación",
     ylab = "Distancia de Cook",
     pch = 19, col = "blue", ylim=c(min(cooks_distance)*.9,max(cooks_distance)*1.05))
abline(h = cooks_threshold, col = "red", lwd = 2, lty = 2)
text(which(cooks_distance > cooks_threshold), cooks_distance[cooks_distance > cooks_threshold],
     labels = which(cooks_distance > cooks_threshold), pos = 3, col = "red")

```

Graficar DFFITS

```{r}
# Graficar DFFITS
plot(dffits_values,
     main = "DFFITS",
     xlab = "Índice de Observación",
     ylab = "DFFITS",
     pch = 19, col = "green", ylim=c(min(dffits_values)*.85,max(dffits_values)*1.07))
abline(h = c(dffits_threshold, -dffits_threshold), col = "red", lwd = 2, lty = 2)
text(which(abs(dffits_values) > dffits_threshold), dffits_values[abs(dffits_values) > dffits_threshold],
     labels = which(abs(dffits_values) > dffits_threshold), pos = 3, col = "red")

```

## Regresión lineal múltiple (Lucía)


### Ajuste del modelo de Regresión Lineal Múltiple

Ajustamos un modelo de regresión lineal múltiple para predecir el número total de interacciones (Total Interactions) en función de todas las variables disponibles.

```{r}
# Ajustar el modelo de regresión lineal múltiple
modelo_facebook <- lm(`Total Interactions` ~ ., data = train_clean)

# Mostrar el resumen del modelo
summary(modelo_facebook)

```
Los valores p permiten identificar qué variables son estadísticamente significativas. Cuanto menor sea p, más significativa será esa variable a la hora de predecir el número total de interacciones.

Comment, like y share tienen valores p extremadamente pequeños (prácticamente 0). Esto de debe a que Total Interactions es simplemente la suma de estas tres variables.

TypeStatus, Paid y Lifetime Post Total Impressions también resultan ser significativos, ya que su p-valor es prácticamente 0. TypeStatus tiene un efecto positivo (coeficiente positivo), lo que indica que las publicaciones de tipo "Status" generan más interacciones. En cambio, paid tiene un efecto negativo (coeficiente negativo), lo que sugiere que las publicaciones patrocinadas reciben menos interacciones totales.


### Selección de variables para optimizar el modelo
```{r}
# Método Stepwise para selección de variables
modelo_stepwise <- step(modelo_facebook, direction = "both", trace = 0)

# Resumen del modelo optimizado
summary(modelo_stepwise)
```


### Evaluación del modelo con Validación Cruzada

Usaremos validación cruzada k-fold para evaluar la capacidad predictiva del modelo. Dividiremos el conjunto de datos en 10 particiones (folds), utilizando 9 para entrenar y 1 para probar, repitiendo este proceso 10 veces.

```{r}
library(caret)

# Configuración de la validación cruzada de 10-fold
control <- trainControl(method = "cv", number = 10)

# Ajuste del modelo con validación cruzada usando caret
modelo_cv <- train(`Total Interactions` ~ .,  # Usar backticks si hay espacios
                   data = train_clean, 
                   method = "lm", 
                   trControl = control)

# Resultados de la validación cruzada
print(modelo_cv)

```
La salida muestra métricas como el RMSE (Root Mean Squared Error) y el R², que miden la capacidad del modelo para predecir correctamente el consumo de combustible. Un RMSE bajo y un R² alto indican un buen rendimiento del modelo.

En este caso vemos que el tamaño de las muestras en cada iteración varía ligeramente entre 222 y 223 observaciones.

R² = 1 significa que el modelo explica el 100% de la variabilidad en la variable objetivo, lo que indica que los predictores usados son suficientes para hacer predicciones perfectas.

RMSE ≈ 0 y MAE ≈ 0 indican que las predicciones son prácticamente idénticas a los valores reales.
`

### Análisis de residuos

```{r}
# Residuals vs Fitted
plot(modelo_facebook, which = 1) 
```

El gráfico de residuals vs Fitted (Residuos vs Valores Ajustados) muestra si los residuos presentan algún patrón sistemático en función de los valores ajustados. En un buen modelo, los residuos deberían estar dispersos alrededor de la línea horizontal (en 0). En cambio, parece haber una ligera curva en los residuos, especialmente en valores más altos.

```{r}
# Q-Q Plot
plot(modelo_facebook, which = 2) 
```

El QQ-plot ayuda a verificar si los residuos siguen una distribución normal. En ese caso, los puntos deberíann alinearse en la diagonal punteada. Vemos que en los valores extremos (colas), los puntos se desvían bastante de la línea diagonal. Esto sugiere que los residuos no son perfectamente normales y que hay valores atípicos o colas más pesadas de lo esperado en una distribución normal.

```{r}
 # Scale-Location
plot(modelo_facebook, which = 3)
```

El gráfico Scale-Location evalúa si la varianza de los residuos es constante. Observamos que hay cierta tendencia ascendente, lo que sugiere  heterocedasticidad, es decir, los residuos no tienen una varianza constante.

```{r}
# Residuals vs Leverage
plot(modelo_facebook, which = 5) 
```

Por último, el gráfico Residuals vs Leverage ayuda a identificar puntos atípicos e influyentes en el modelo. Hay algunos puntos con leverage alto y residuos grandes, lo que sugiere que pueden ser valores atípicos o datos muy influyentes en el modelo.


```{r}
# Prueba de normalidad de los residuos
shapiro.test(residuals(modelo_facebook))
```

La prueba de Shapiro-Wilk evalúa la normalidad de los residuos, al igual que el Q-Q Plot anterior.

La hipótesis nula (H0) establece que los residuos siguen una distribución normal.

Hemos obtenido un p-valor = 2.2e-16. Como el p-valor es menor que 0.05, tenemos suficiente evidencia estadística para rechazar la hipótesis nula. Esto indica que los residuos NO siguen una distribución normal, confirmando lo que vimos con el Q-Q Plot.


```{r}
# Prueba de homocedasticidad (Breusch-Pagan)
library(lmtest)
bptest(modelo_facebook)
```

La prueba de Breusch-Pagan verifica la homocedasticidad de los residuos, es decir, si la varianza de los errores es constant, al igual que el gráfico Scale-Location.

La hipótesis nula (H0) establece que los residuos tienen varianza constante (homocedasticidad).

Hemos obtenido un p-valor = 4.776e-14. Como el p-valor es menor que 0.05, tenemos suficiente evidencia estadística para rechazar la hipótesis nula. Esto sugiere que los residuos NO tienen varianza constante, es decir, existe heterocedasticidad en el modelo.

### Diagnóstico de Multicolinealidad y observaciones influyentes

La multicolinealidad puede afectar la estabilidad de los coeficientes del modelo. Además, es importante identificar observaciones influyentes que puedan distorsionar los resultados.


```{r}
library(car)

# Diagnóstico de multicolinealidad usando el VIF (Variance Inflation Factor)
vif(modelo_facebook)
```
Un VIF mayor que 5 indica la presencia de multicolinealidad.

```{r}
# Identificación de observaciones influyentes utilizando la distancia de Cook
influencia <- cooks.distance(modelo_facebook)

# Visualización de observaciones influyentes
plot(influencia, type = "h", main = "Distancia de Cook", ylab = "Influencia")
abline(h = 4/(nrow(train) - length(modelo_facebook$coefficients)), col = "red")

```

La distancia de Cook permite identificar observaciones que tienen una gran influencia en los resultados del modelo. Valores por encima de la línea roja deben ser investigados.


# Métodos de selección de variables y problemas de regularización 

## LASSO (Cristina)

A la hora de realizar LASSO hemos quitado las variables "comment", "like" y "share" (aparte del target), ya que nuestro target es el resultado de la suma de estas tres variables.

```{r}
library(glmnet)

# Eliminar filas NA y definir variable dependiente e independientes
train_clean <- na.omit(train)

# Definir Y (variable objetivo) como "Total Interactions"
Y <- train_clean$`Total Interactions`

# Definir X (matriz de variables predictoras) excluyendo la variable objetivo
X <- train_clean[, !names(train_clean) %in% c("Total Interactions", "comment", "like", "share")]

# Eliminar todas las variables categóricas de X
X <- X[sapply(X, is.numeric)]

# Convertir X a matriz numérica para glmnet
X <- as.matrix(X)

```



```{r}
# Ajustar el modelo Lasso
modelo_lasso <- glmnet(X, Y, alpha = 1)

# Seleccionar el mejor lambda usando validación cruzada
cv_lasso <- cv.glmnet(X, Y, alpha = 1)
lambda_optimo <- cv_lasso$lambda.min  # Mejor valor de lambda

# Ajustar modelo final con lambda óptimo
modelo_lasso_final <- glmnet(X, Y, alpha = 1, lambda = lambda_optimo)

# Mostrar coeficientes del modelo
coeficientes_lasso <- coef(modelo_lasso_final)
print(coeficientes_lasso)

```
+ Las variables "Paid" y "Lifetime Engaged Users" tienen un impacto positivo fuerte y significativo en las interacciones totales.

+ Variables como "Page total likes" y "Lifetime Post Total Reach" tienen un impacto muy pequeño, lo que sugiere que no son tan relevantes para predecir las interacciones.

+ Las variables como "Post Month", "Lifetime Post Consumers" y "Lifetime Post reach by people who like your Page" tienen efectos negativos sobre las interacciones totales.

+ Lasso ha reducido el número de variables que influyen en el modelo, eliminando las que no aportan valor predictivo.


## Ridge (Lucía)


## Justificar las elecciones y comparar modelos


# Modelos no lineales (Alonso)

## necesidad de modelos no lineales
## transformaciones de variables
## Evaluar mejoras con métricas

